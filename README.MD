<p>In pursuit of a comprehensive understanding of Transformers, I embarked on a project to build one from the very foundation. This ambitious endeavor was centered around creating a custom Transformer architecture, serving as an invaluable learning experience. The project's primary goal was to leverage this self-built Transformer for sentiment classification, a task that demands a profound comprehension of the model's inner workings. Through this hands-on journey, I delved into the intricacies of attention mechanisms, positional encodings, and the entire Transformer Encoder architecture, ultimately gaining a deep and holistic insight into this groundbreaking technology.</p>
